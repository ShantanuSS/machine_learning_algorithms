{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (768, 9)\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "\n",
      "Data Description:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"data/diabetes.csv\")\n",
    "# Printing shape of data\n",
    "print(\"Shape of data: \", data.shape)\n",
    "# Displaying data information\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nData Description:\")\n",
    "print(data.describe()) # Here only integer and float columns are only considered\n",
    "# from sklearn import datasets\n",
    "# data = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_train_and_test():\n",
    "    \"\"\"\n",
    "    - Split dataset between train and test dataset\n",
    "    \"\"\"\n",
    "    train = data.sample(frac=0.8, random_state=1) # Get random 80% of data\n",
    "    # print(train.index)\n",
    "    test = data.drop(train.index) # Get remaining data, after dropping rows of indexes which are present in train\n",
    "    X_train = train.iloc[:, :-1].values\n",
    "    y_train = train.iloc[:, -1:].values.flatten()\n",
    "    \n",
    "    X_test = test.iloc[:, :-1].values\n",
    "    y_test = test.iloc[:, -1:].values.flatten()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Entropy formula](images/entropy_general.png)\n",
    "\n",
    "Where p(X) is % of given sample wrt all samples. Given by formula: number of given sample/total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def calculate_entropy(y):\n",
    "    # Get number of occurences of all class labels\n",
    "    h = np.bincount(y)  # bincount gives an numpy array containing frequency of numbers in ascending order.\n",
    "    # Instead of above, we can also use:  _, counts = np.unique(y_train, return_counts=True); then `counts` will give same result\n",
    "    # print(h): array([403, 211])\n",
    "\n",
    "    # Then divide them by length of total samples to get the probability(or percentage), it will also give numpy array where each element is\n",
    "    # division of ith element of `h` / length of y   \n",
    "    px = h/len(y)\n",
    "    # print(px): array([0.65635179, 0.34364821])\n",
    "    \n",
    "    # Now calculate entropy using its formula\n",
    "    #entropy = -(sum(px * np.log2(px)))\n",
    "    return -np.sum([p * np.log2(p) for p in px if p > 0])\n",
    "\n",
    "\n",
    "# To store a info of a node\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None,right=None, *, value=None):\n",
    "        # We are using * as if we have to use value parameter, we have to use using keyword only parameter\n",
    "        # So for a leaf node when we just have value, then we can use this\n",
    "        # For every other node, other than leaf node, value will be None \n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def check_leaf_node(self):\n",
    "        \"\"\"\n",
    "         Detects whether node is leaf node or not\n",
    "        \"\"\"\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, num_features=None):\n",
    "        self.root = None  # Starting node\n",
    "        self.min_samples_split = min_samples_split  # minimum samples require to split a tree \n",
    "        self.max_depth = max_depth\n",
    "        self.num_features = num_features  # If we don't want to include all the given features in input dataset\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        - First method to be called when building the tree in training phase\n",
    "        \"\"\"\n",
    "        # If self.features was not specified then we will take maximum no. of features, \n",
    "        # or if features are less than specified values,then we just consider min value\n",
    "        # Here for now we are getting all 8 features\n",
    "        self.num_features = X.shape[1] if not self.num_features else min(self.num_features, X.shape[1])\n",
    "        self.root = self.grow_tree(X, y)\n",
    "\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):  # Intially depth = 0(Starting at root)\n",
    "        n_samples, n_features = X.shape\n",
    "        # Get all different labels\n",
    "        n_labels = len(np.unique(y))\n",
    "        \"\"\"\n",
    "        Stoppig criteria:\n",
    "            - Reached max depth, or\n",
    "            - minimum samples not found at node(required sample count became less than min number of sample count)\n",
    "            - No more class distribution            \n",
    "        \"\"\"\n",
    "        # If it is leaf node or any stopping criteria is found\n",
    "        if depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            # If any of these conditions is true it means leaf node has been reached\n",
    "            # Here we save the node with that y_label value whose count is more\n",
    "            #print(depth, n_labels, n_samples)\n",
    "            leaf_value = self.get_most_common_label(y)\n",
    "            #print(\"##\", leaf_value)\n",
    "            return Node(value=leaf_value)  # This is the leaf node as we are just using value keyword\n",
    "\n",
    "        # Select some random features every time for split,\n",
    "        # np,random.choice generates a random sample from a given 1-D array\n",
    "        # if n_features = self.num_features, then all features will be given in an array in random order\n",
    "        features_idxs = np.random.choice(n_features, self.num_features, replace=False) # array, size, replace (keep False as we don't want same index multiple times)\n",
    "        # Returns best feature and threshold value\n",
    "        best_feature, best_threshold = self.get_best_split(X, y, features_idxs, n_samples)  # Greedy search\n",
    "        #if n_samples == 17:\n",
    "        #    print(features_idxs)\n",
    "        #    import sys\n",
    "        #    sys.exit(0)\n",
    "\n",
    "        # Split tree wrt best feature and threshold\n",
    "        left_idx, right_idx = self.split(X[:, best_feature], best_threshold)  # Return ids of X features having \n",
    "        # left_idx contains indices of indices of array(X) elements that were less than threshold and right_idx contain elements indices whose value were more than threshold\n",
    "\n",
    "        # Now we can continuing growing\n",
    "        left = self.grow_tree(X[left_idx, :], y[left_idx], depth+1)\n",
    "        right = self.grow_tree(X[right_idx, :], y[right_idx], depth+1)\n",
    "        \n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "\n",
    "\n",
    "    def get_most_common_label(self, y):\n",
    "        #counts = np.bincount(y) # It will give frequency of all values of y\n",
    "        #print(y)\n",
    "        #print(counts)#:  array([403, 211]); 403 is count of 0 and 211 is of 1\n",
    "        #most_common = np.argmax(counts)\n",
    "        # print(most_common):  0\n",
    "        #return most_common\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "\n",
    "\n",
    "    def get_best_split(self, X, y, features_idxs, n_samples):\n",
    "        \"\"\"\n",
    "        To get the best split among all given features, using information gain\n",
    "        \"\"\"\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "        for features_idx in features_idxs:\n",
    "            # Now select only column vector at only selected index\n",
    "            X_column = X[:, features_idx]\n",
    "            #if n_samples == 17:\n",
    "            #    print(X_column)\n",
    "            # Get only unique values in a numpy array for X_column\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                gain = self.get_info_gain(X_column, y, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = features_idx\n",
    "                    split_threshold = threshold\n",
    "                    \n",
    "        return split_idx, split_threshold\n",
    "\n",
    "    \n",
    "    def get_info_gain(self, X_column, y, split_threshold):\n",
    "        # Calculate parent entropy\n",
    "        parent_entropy = calculate_entropy(y)\n",
    "        # Generate split\n",
    "        left_idx, right_idx = self.split(X_column, split_threshold)\n",
    "        if len(left_idx) == 0 or len(right_idx) == 0:\n",
    "            return 0\n",
    "        # Calculate weighted average of child entropies\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idx), len(right_idx)\n",
    "        e_l, e_r = calculate_entropy(y[left_idx]), calculate_entropy(y[right_idx])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "        \n",
    "        # Calculate information gain\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "\n",
    "    def split(self, X_column, split_threshold):\n",
    "        left_idx = np.argwhere(X_column <= split_threshold).flatten() # Return array where condition is true and flatten it to get 1D array\n",
    "        right_idx = np.argwhere(X_column > split_threshold).flatten() # Return array where condition is true and flatten it to get 1D array\n",
    "\n",
    "        return left_idx, right_idx\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Traverse tree\n",
    "        return np.array([self.traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.check_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_into_train_and_test()\n",
    "# # X_train\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X = data.data\n",
    "# y = data.target\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# # x = data.iloc[:, :-1].values\n",
    "# # y = data.iloc[:, -1:].values\n",
    "\n",
    "# # #spliting the dataset into training and test set\n",
    "# # x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    \"\"\"\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTree(max_depth=10)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+01, 1.15e+02, 0.00e+00, ..., 3.53e+01, 1.34e-01, 2.90e+01],\n",
       "       [4.00e+00, 1.10e+02, 9.20e+01, ..., 3.76e+01, 1.91e-01, 3.00e+01],\n",
       "       [7.00e+00, 1.00e+02, 0.00e+00, ..., 3.00e+01, 4.84e-01, 3.20e+01],\n",
       "       ...,\n",
       "       [6.00e+00, 1.62e+02, 6.20e+01, ..., 2.43e+01, 1.78e-01, 5.00e+01],\n",
       "       [1.00e+00, 1.06e+02, 7.60e+01, ..., 3.75e+01, 1.97e-01, 2.60e+01],\n",
       "       [2.00e+00, 1.22e+02, 7.00e+01, ..., 3.68e+01, 3.40e-01, 2.70e+01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "acc = get_accuracy(y_test, y_pred)\n",
    "print (\"Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mldl] *",
   "language": "python",
   "name": "conda-env-mldl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
